# QUIZLY-APP
The Multimodal Android Quiz Application is a project aimed at developing an interactive quiz application that utilizes hand gestures and gaze tracking for selecting quiz answers. The application incorporates various technologies, including Figma for UI/UX design, React Native for front-end development, MongoDB for database management, Express and Node.js for backend development, Python for machine learning models, and APIs for model integration. Convolutional Neural Networks (CNNs) are used for model training.
## Objectives
The objectives of the project are as follows:
1. Develop a user-friendly and visually appealing UI/UX design using Figma.
2. Implement the front-end of the application using React Native.
3. Manage the database using MongoDB for efficient data storage and retrieval.
4. Build the backend using Express and Node.js to handle application logic and API integration.
5. Utilize Python for training machine learning models for quiz answer recognition.
6. Integrate the machine learning models with APIs to enable real-time quiz answer selection.
7. Employ CNNs for model training to achieve high accuracy.
8. Implement hand gesture recognition to allow users to select quiz answers using gestures.
## Images
![image](https://github.com/zshafique25/QUIZLY-APP/assets/127844420/6347178a-de68-47ff-afb8-d3362a0a6ad8)
![image](https://github.com/zshafique25/QUIZLY-APP/assets/127844420/08219e0e-1aba-4a58-89f3-6539b1e0620b)
## Demo Video
Demo Video Link: https://drive.google.com/drive/folders/1KCmJev2TkMfPkxZ5iwlgKbUSJdSevLQR?usp=sharing
